[{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/idcheck.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"ID Correction and Autobot","text":"example (fake) farm_id identifier. can see ID checker functions corrected ‘O’ ‘0’ record 2. Case correction taken place, records conform required pattern post corrections, set NA manual review.","code":"# A tibble: 6 × 2   farm_id    farm_id_new   <chr>      <chr>       1 123ABC0007 NA          2 1O3ABC010  103ABC010   3 143abc010  143ABC010   4 13DEFH005  NA          5 243DLF803  243DLF803   6 243DPF911  243DPF911 > ohcleandat::autobot(data = test, old_col = \"farm_id\", new_col = \"farm_id_new\", key = \"farm_id\") # A tibble: 2 × 8   entry     field   issue                               old_value no_change new_val  user_initials comments   <chr>     <chr>   <chr>                               <chr>     <chr>    <chr>    <chr>         <chr>    1 1O3ABC010 farm_id Automated field format check failed 1O3ABC010 FALSE    103ABC0… autobot       \"\"       2 143abc010 farm_id Automated field format check failed 143abc010 FALSE    143ABC0… autobot       \"\""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/integration.html","id":"integrating-data-sets","dir":"Articles","previous_headings":"","what":"Integrating Data Sets","title":"Integrating Different Datasets","text":"individual data set passed cleaning validation process, may need combined (joined) data sets. process handled {targets} pipeline integration steps. two phases, first performing checks second join operation. checks perform tests ensure records data sets compatible match expectations relationship two data sets. Secondly, integration data sets performed using SQL join operation. typically either right-join, left-join, inner-join full-join. type join operation selected depends relationship data sets. critical information primary-key (unique identifier) base table foreign-key table joined attribute match primary-key. addition, cardinality relationship important understand expected result joining data. example entity relationship diagram shows relationship two example data sets. Crow’s feet notation used illustrate optional 1:Many relationship left table right table. also mandatory 1:1 relationship right table left table.  Also relevant target performs joining operation integrates data sets together. critical data validation steps correctly performed ensure integration multiple data sets successful. case missing, malformed duplicate primary key, expectations around relationship type hold . overview integration process .","code":"tar_target(integrated_mosq_field,              left_join(                x = fs_mosquito_field_semiclean,                y = longitudinal_identification_semiclean,                by =  c(\"Batch_ID\" = \"batch_id\")              )   )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/integration.html","id":"types-of-data","dir":"Articles","previous_headings":"","what":"Types of Data","title":"Integrating Different Datasets","text":"Throughout data cleaning pipeline, take raw data convert form clean data. several intermediate steps process. standard terminology adopted describe steps process. raw data: data read directly source systems. combined data: raw data situated multiple files data frames, compatible united data set data termed ‘combined.’ semi-clean: Data semi-clean corrected using values provided validation log. integrated: Data integrated joined data sets. clean: Data termed clean integrated, records still pending validation logs removed, thereby leaving clean subset validated data.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/integration.html","id":"tips-for-data-management","dir":"Articles","previous_headings":"","what":"Tips for data management","title":"Integrating Different Datasets","text":"course long data collection exercise, standards formats can diverge. makes data cleaning steps difficult slow ability integrate data . general strategies can help mitigate risks: Ensure data formatting standard row uniquely identifies record unique identifier without duplicates missing values. Ensure data stored data.frame tibble. R, ensure column correct unique column type. (.e. character, numeric list) column name unique formatted consistently avoid spaces special characters column names. Hint: Use janitor::clean_names(). Design enforce Primary Key Unique Identifier data set meaningful immutable. Think storing data ‘tidy’ format possible. See : https://www.jstatsoft.org/article/view/v059i10 Store raw data machine readable format (.e. CSV) Set metadata standards start project around columns data types. understandable might change time, standards help plan best accommodate changes without breaking existing work.","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/mechanics.html","id":"reading-raw-data","dir":"Articles","previous_headings":"Data Cleaning and Validation Pipeline","what":"Reading raw data","title":"Mechanics: Data Cleaning and Validation Pipeline","text":"raw data pipeline can variety sources. first step read data, standardize using pre-processing steps required, combine one unified data set review.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/mechanics.html","id":"validation-rules","dir":"Articles","previous_headings":"Data Cleaning and Validation Pipeline","what":"Validation Rules","title":"Mechanics: Data Cleaning and Validation Pipeline","text":"Data validation rules formally defined using {validate} R package. rules might involve ensuring data within certain range, ensuring values given input list checking see values unique missing.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/mechanics.html","id":"validation-log","dir":"Articles","previous_headings":"Data Cleaning and Validation Pipeline","what":"Validation Log","title":"Mechanics: Data Cleaning and Validation Pipeline","text":"rules defined, ‘confronted’ data. records pass validation checks exported validation log. validation log CSV output can sent subject-matter experts manual review. review process, reviewer indicate entry valid , , provide ‘new value’ corrected well optional comments.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/mechanics.html","id":"integrating-corrections","dir":"Articles","previous_headings":"Data Cleaning and Validation Pipeline","what":"Integrating corrections","title":"Mechanics: Data Cleaning and Validation Pipeline","text":"final step involves correcting data converting ‘semi-clean’ data set. involves reading validation log, scanning changes indicated, correcting existing values newly supplied values. ensure corrections applied expected, function validation_checks() provided compare data, along validation logs. function error checks satisfied output successful summary output arsenal::comparedf(). conceptual overview process outlined .","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/mechanics.html","id":"pipeline","dir":"Articles","previous_headings":"Targets Implementation","what":"Pipeline","title":"Mechanics: Data Cleaning and Validation Pipeline","text":"code sample demonstrates typical end end validation pipeline. data pre-processing steps given project may vary, much code can re-used template future pipelines.","code":"fs_mosquito_field_targets <- tar_plan(   # FS mosquito field data googlesheets ids   targets::tar_target(     fs_mosquito_field_sheets,     c(       fs_mosquito_21_24 = \"1I45IcVtYi7hOc-qum7d\",       fs_mosquito_19_20 = \"17hYyE_Rs4Z9IU-vpKTj\",       fs_mosquito_20_21 = \"1qn_N0WVTKpwv0iKzOEm\",       fs_mosquito_16_17 = \"1XAItM-YST8ZdUCU1gPH\",       fs_mosquito_17_18 = \"1GUYgEX-VA0NH2_Yko-M\",       fs_mosquito_18_19 = \"1HJv9-DOQ3sOgy3wVHoz\"     )   ),      # FS mosquito field data 2021-2024   targets::tar_target(     fs_mosquito_field_raw,     ohcleandat::read_googlesheets(       key_path = here::here(\"./key.json\"),       ss = fs_mosquito_field_sheets,       sheet = \"all\"     ),     pattern = map(fs_mosquito_field_sheets),     iteration = \"list\",     cue = tar_cue(\"never\")   ),      # setting intuitive names for the dynamic branches of each year   tar_target(     fs_mosquito_field_raw_n,     set_names(fs_mosquito_field_raw, names(fs_mosquito_field_sheets))   ),      # clean data   targets::tar_target(     fs_mosquito_21_24,     map_dfr(       fs_mosquito_field_raw_n$fs_mosquito_21_24[1:5],       clean_fs_mosquito_21_24     )   ),      targets::tar_target(     fs_mosquito_19_20,     map_dfr(       fs_mosquito_field_raw_n$fs_mosquito_19_20[1:5],       clean_fs_mosquito_19_20     )   ),      targets::tar_target(     fs_mosquito_20_21,     map_dfr(       fs_mosquito_field_raw_n$fs_mosquito_20_21[-5],       clean_fs_mosquito_20_21     )   ),      targets::tar_target(     fs_mosquito_16_17,     map_dfr(       fs_mosquito_field_raw_n$fs_mosquito_16_17[-c(3, 24, 25)],       clean_fs_mosquito_16_17     )   ),      targets::tar_target(     fs_mosquito_17_18,     map_dfr(       fs_mosquito_field_raw_n$fs_mosquito_17_18,       clean_fs_mosquito_17_18     )   ),      targets::tar_target(     fs_mosquito_18_19,     map_dfr(       fs_mosquito_field_raw_n$fs_mosquito_18_19[1:23],       clean_fs_mosquito_18_19     )   ),      # combine all years   targets::tar_target(     fs_mosquito_data_comb,     bind_rows(       fs_mosquito_21_24 = fs_mosquito_21_24,       fs_mosquito_19_20 = fs_mosquito_19_20,       fs_mosquito_20_21 = fs_mosquito_20_21,       fs_mosquito_16_17 = fs_mosquito_16_17,       fs_mosquito_17_18 = fs_mosquito_17_18,       fs_mosquito_18_19 = fs_mosquito_18_19,       .id = \"dataset\"     )   ),      # post processing   targets::tar_target(     fs_mosquito_data,     combine_fs_mosquito_field(fs_mosquito_data_comb)   ),      # read in existing validation log if exists   targets::tar_target(     fs_mosquito_field_existing_log,     ohcleandat::get_dropbox_val_logs(       file_name = \"log_fs_mosquito_field.csv\",       path_name = \"dropbox/validation_logs\",       folder = NULL     ),     cue = targets::tar_cue(\"always\")   ),      # clean the data using the existing validation log   targets::tar_target(     fs_mosquito_field_semiclean,     ohcleandat::correct_data(       validation_log = fs_mosquito_field_existing_log,       data = fs_mosquito_data,       primary_key = \"key\"     )   ),      #   # validation cleaning checks   targets::tar_target(     fs_mosquito_field_cleaning_checks,     ohcleandat::validation_checks(       validation_log = fs_mosquito_field_existing_log,       before_data = fs_mosquito_data,       after_data = fs_mosquito_field_semiclean     )   ),      # upload semiclean data   targets::tar_target(     upload_fs_mosquito_field_semiclean,     ohcleandat::dropbox_upload(       fs_mosquito_field_semiclean,       file_path = here::here(\"outputs/semiclean_fs_mosquito_field.csv\"),       dropbox_path = \"dropbox/semi_clean_data\"     ),     cue = targets::tar_cue(\"always\")   ),      # Initializing rules which are defined as a function   targets::tar_target(rules_fs_mosquito_field, create_rules_fs_mosquito_field()),      # mapping through rules to create a validation log   targets::tar_target(     log_fs_mosquito_field,     map_df(       rules_fs_mosquito_field[-c(13, 14)],       ~ ohcleandat::create_validation_log(         data = fs_mosquito_field_semiclean,         rule_set = .x,         pkey = \"key\"       )     )   ),      # Combine new validation violations with existing log   targets::tar_target(     log_fs_mosquito_field_combined,     ohcleandat::combine_logs(existing_log = fs_mosquito_field_existing_log, new_log = log_fs_mosquito_field)   ),      # uploading to dropbox   targets::tar_target(     upload_log_fs_mosquito_field_dropbox,     ohcleandat::dropbox_upload(       log = log_fs_mosquito_field_combined,       file_path = here::here(\"outputs/log_fs_mosquito_field.csv\"),       dropbox_path = \"dropbpx/validation_logs\"     ),     cue = targets::tar_cue(\"always\")   ),      # Rendering a HTML report for archival and emailing   tarchetypes::tar_render(     report_fs_mosquito_field,     path = here::here(\"reports/RVF2_FS_Mosquito_Field.Rmd\"),     output_dir = \"outputs\",     knit_root_dir = here::here()   ),      # target to identify report path   targets::tar_target(     html_files_fs_mosquito_field,     containerTemplateUtils::get_file_paths(report_fs_mosquito_field, pattern = \"\\\\.html$\")   ),      # Upload and archive report to AWS S3   targets::tar_target(     deploy_automations_report_fs_mosquito_field,     containerTemplateUtils::aws_s3_upload(       path = html_files_fs_mosquito_field,       prefix = sprintf(\"%s%s/\", git_prefix, Sys.Date()),       bucket = Sys.getenv(\"AWS_BUCKET\"),       error = TRUE,       file_type = \"html\"     ),     cue = targets::tar_cue(\"always\")   ),      # Create a custom URL for hyperlink   targets::tar_target(     url_fs_mosquito_field,     ohcleandat::make_report_urls(deploy_automations_report_fs_mosquito_field)   ),      # Blast out email   targets::tar_target(     name = email_updates_fs_mosquito_field,     command =       containerTemplateUtils::send_email_update_tar(         to = strsplit(Sys.getenv(\"EMAIL_RECIPIENTS_TEST\"), \";\")[[1]],         from = Sys.getenv(\"EMAIL_SENDER\"),         project_name = \"RVF1 & RVF2 FS Mosquito Field data\",         attach = TRUE,         attachment_paths = html_files_fs_mosquito_field,         use_hyperlinks = TRUE,         hyperlinks_text = \"Archived Report\",         hyperlinks_url = url_fs_mosquito_field,         test = TRUE       ),     cue = targets::tar_cue(\"always\")   ) )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/mechanics.html","id":"dag","dir":"Articles","previous_headings":"Targets Implementation","what":"DAG","title":"Mechanics: Data Cleaning and Validation Pipeline","text":"directed acyclic graph {targets} pipeline shown real example.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/mechanics.html","id":"revised-pipeline","dir":"Articles","previous_headings":"Targets Implementation","what":"Revised pipeline","title":"Mechanics: Data Cleaning and Validation Pipeline","text":"actual fact, reading targets pipeline, refinement required flow chart reflect pipeline works beyond initial creation. ensure validation log corrections applied correctly, existing validation log read first. raw data corrected validation log re-run ‘semi-clean’ data flag new violations already reviewed corrected. new violation appended existing log uploaded Dropbox.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/mechanics.html","id":"complex-cases","dir":"Articles","previous_headings":"","what":"Complex Cases","title":"Mechanics: Data Cleaning and Validation Pipeline","text":"cases, questionnaire data, multiple different logs created combined together - increasing complexity. example combining multiple log types together:","code":"# mapping through rules to create a validation log targets::tar_target(   log_animal_owner,   map_df(     rules_animal_owner,     ~ ohcleandat::create_questionnaire_log(       data = animal_owner_semiclean,       form_schema = animal_owner_schema,       rule_set = .x,       url = \"https://odk.xyz.io/#/projects/5/forms/survey/submissions\",       pkey = \"id\"     )   ) ),  # create validation log records for free text requiring translation targets::tar_target(   animal_owner_translation_log,   ohcleandat::create_translation_log(     response_data = animal_owner_semiclean,     form_schema = animal_owner_schema,     url = \"https://odk.xyz.io/#/projects/5/forms/survey/submissions\",   ) ),  # create validation log records for free text 'other' responses that may contain valid multi-options targets::tar_target(   animal_owner_text_log,   ohcleandat::create_freetext_log(     response_data = animal_owner_semiclean,     form_schema = animal_owner_schema,     url = \"https://odk.xyz.io/#/projects/5/forms/survey/submissions\",     ,     questionnaire = \"animal_owner\"   )    ),  # unite current-run logs targets::tar_target(   logs_all_animal_owner,   bind_rows(     log_animal_owner,     animal_owner_translation_log,     animal_owner_text_log   ) ),  # Combine new validation violations with existing log targets::tar_target(   log_animal_owner_combined,   ohcleandat::combine_logs(existing_log = animal_owner_existing_log, new_log = logs_all_animal_owner) )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/mechanics.html","id":"more-info","dir":"Articles","previous_headings":"","what":"More info","title":"Mechanics: Data Cleaning and Validation Pipeline","text":"info using {targets} see : https://ecohealthalliance.github.io/eha-ma-handbook/3-projects.html#targets","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/metadata.html","id":"creating-structural-metadata-with-ohcleandat","dir":"Articles","previous_headings":"","what":"Creating structural metadata with {ohcleandat}","title":"Metadata: Creating Standard Metadata with `{ohcleandat}` and `{deposits}`","text":"{ohcleandat} largely deals cleaning tabular data, can use standard (extensible) structural metadata format describe outputs. basic structural metadata table produced following elements name = name field. taken data. description = Description field. May provided controlled vocabulary units = Units measure field. May may apply term_uri = Universal Resource Identifier term controlled vocabulary schema comments = Free text providing additional details field primary_key = TRUE FALSE, Uniquely identifies record data foreign_key = TRUE FALSE, Allows linkages data sets. Uniquely identifies records different data set Additional metadata elements can added creating column binding empty data.frame basic structure.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/metadata.html","id":"basic-example","dir":"Articles","previous_headings":"Creating structural metadata with {ohcleandat}","what":"Basic Example:","title":"Metadata: Creating Standard Metadata with `{ohcleandat}` and `{deposits}`","text":"","code":"## read in your data data_to_describe <- tibble::tibble(date = as.Date(19961:19970),                                    measurement = sample(1:100,10),                                    measured_by = sample(c(\"Collin\",\"Johana\"),size = 10,replace = TRUE),                                    site_name = sample(letters[1:5],size = 10,replace = TRUE),                                    field_we_dont_need = \"nothing useful here\" )  # create metadata structural_metadata  <- ohcleandat::create_structural_metadata(data_to_describe)  # write to csv structural_metadata |>   write.csv(file = \"metadata_examples/structural_metadata.csv\",row.names = FALSE)  # Fill in metadata by hand and read  structural_metadata_complete <- readr::read_csv(file = \"metadata_examples/structural_metadata_complete.csv\")"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/metadata.html","id":"what-if-the-structure-of-my-data-change","dir":"Articles","previous_headings":"Creating structural metadata with {ohcleandat}","what":"What if the structure of my data change?","title":"Metadata: Creating Standard Metadata with `{ohcleandat}` and `{deposits}`","text":"re-write metadata? Maybe! certain cirucumstances can just update metadata.","code":"## oops I forgot to add a primary key data_to_describe$key <- 1:10   # add primary key and label it as a primary key in the metadata  structural_metadata_pk<- ohcleandat::update_structural_metadata(data = data_to_describe,metadata = structural_metadata_complete, primary_key = \"key\")  # oh also, the measured_by field is a foreign key  structural_metadata_fk <- ohcleandat::update_structural_metadata(data = data_to_describe,                                                                  metadata = structural_metadata_pk,                                                                   foreign_key = \"measured_by\")  ## yeah we deleted that field - sorry!  data_to_describe_drop_field <- data_to_describe |>   dplyr::select(-field_we_dont_need)  structural_metadata_clean <- ohcleandat::update_structural_metadata(   data = data_to_describe_drop_field,   metadata = structural_metadata_fk)  write.csv(structural_metadata_clean,           file = \"metadata_examples/structural_metadata.csv\",           row.names = FALSE)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/metadata.html","id":"depositing-data-into-an-archive-with-deposits","dir":"Articles","previous_headings":"","what":"Depositing data into an archive with {deposits}","title":"Metadata: Creating Standard Metadata with `{ohcleandat}` and `{deposits}`","text":"Okay - want deposit data using {deposits} package. {deposits} uses frictionless data standard end thing called datapackage.json stores metadata. datapackage.json structural metadata pretty minimal - includes field name type (numeric, character, etc). want add metadata . See {deposits} setup guide getting api token installing package. might also helpful review metadata_template.json file creating descriptive metadata. certain DCMI terms can included descriptive metadata formatting can little tricky.","code":"# set deposits token  # this can also be done in the `.Renviron` file or # via a .env file using the {dotenv} package # dotenv::load_dot_env(file = \"../.env\") Sys.setenv (\"ZENODO_SANDBOX_TOKEN\" = \"<my-token>\")  # make sure your data are saved to a file  write.csv(data_to_describe_drop_field,file = \"data_examples/my_data.csv\",row.names = FALSE)  # make sure your updated metadata file is loaded  structural_metadata <- readr::read_csv(\"metadata_examples/structural_metadata_complete.csv\")   # Create descriptive metadata  # check valid dcmi terms by calling deposits::dcmi_terms() # check see term defintions by calling: deposits::deposits_metadata_template(filename = \"metadata_template.json\")  descriptive_metadata <- list (     title = \"Example Dataset\",     description = \"This is the abstract\",     creator = list (list (name = \"A. Person\"), list (name = \"B. Person\"))     # , accessRights = \"open\" )  # create a new client  cli <- deposits::depositsClient$new(service = \"zenodo\",                                     metadata = descriptive_metadata,                                     sandbox = TRUE)   # create a new deposit item - this  creates a placeholder in zenodo # for your items cli$deposit_new()  # add your data - you can add individual files or whole folders # this will make a datapackage.json item in data_examples cli$deposit_add_resource(path = \"data_examples/my_data.csv\")  ## open the   # Take a peak at the `datapackage.json` file - you'll see the first section # describes the csv file, the second section describes the data in the csv, # the third section contains the descriptive metadata we created  # Add your structural metadata to the frictionless metadata  expand_frictionless_metadata(structural_metadata = structural_metadata,                              resource_name = \"my_data\", # name of the file with no extension                              resource_path = \"data_examples/my_data.csv\",                              data_package_path = \"data_examples/datapackage.json\")    ## OOPs actually I need to add more to the description  descriptive_metadata <- list (     title = \"Example Dataset\",     description = \"This is the abstract but it needs more detail\",     creator = list (list (name = \"A. Person\"), list (name = \"B. Person\"),list (name = \"C. Person\"),list (name = \"F. Person\"))     # , accessRights = \"open\" )   update_frictionless_metadata(descriptive_metadata = descriptive_metadata,                              data_package_path = \"data_examples/datapackage.json\" )  cli$deposit_fill_metadata(descriptive_metadata) # update deposit hangs if the descriptive metadata is not properly formatted, even after correction # upload to zenodo - this creates a **draft** deposit in Zenodo  cli$deposit_upload_file(path = \"data_examples/\")  ## update structural metadata  structural_metadata[1,2] <- \"New description\"  expand_frictionless_metadata(structural_metadata = structural_metadata,                              resource_name = \"my_data\", # name of the file with no extension                              resource_path = \"data_examples/my_data.csv\",                              data_package_path = \"data_examples/datapackage.json\")  ## remove an element from the structural metadata and datapackage  # dropping the comments field  structural_metadata <- structural_metadata[-5]  expand_frictionless_metadata(structural_metadata = structural_metadata,                              resource_name = \"my_data\", # name of the file with no extension                              resource_path = \"data_examples/my_data.csv\",                              data_package_path = \"data_examples/datapackage.json\",                              prune_datapackage = TRUE) # this is the default  # there are methods for embargoing or restricting deposits in {deposits}"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/outputs.html","id":"html-report","dir":"Articles","previous_headings":"","what":"HTML Report","title":"Understanding The Pipeline Outputs","text":"sample HTML report shows . archived AWS S3 secure link produced. details emailed user pre-defined list recipients.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/outputs.html","id":"validation-logs","dir":"Articles","previous_headings":"","what":"Validation Logs","title":"Understanding The Pipeline Outputs","text":"following list fields validation logs meaning: rowid: Provides correct order entries validation log. important users may choose filter change order log order understand appropriately correct records log. However, since changes need processed sequential order, rowid used correction functions data pipeline can appropriately process correct changes data right order. log_response_id: cases, unique identifier record long complicated ID string, easily parsed human. provide easier way filter understand different entries log relate record, simpler log_response_id provides just group ID particular unique record identifier understand records relate . entry: unique identifier particular record data. Otherwise known primary key. key identifier used locate record data apply corrections. field: column name data set relating record described validation log. question: question column exists survey data provides survey question text. issue: human readable description validation rule broken needs corrected. old_value: Indicates current value data pass validation rule. no_change: important column validation log. can take two values. TRUE FALSE (also acceptable T F). particular record validation log needs corrected user must mark FALSE, indicating current value data set valid requires correction. user reviewing validation log despite fact entry log, old value data fact correct, user can place TRUE field indicate record valid require correction. new_val: column human input indicate corrected value. overwrite_old_value: survey questionnaire data , column two options, TRUE FALSE. indicate whether new value completely overwrite old value currently data. set FALSE, new value appended end old_value string. user_initials: enables reviewer provide initials understand reviewer made corrections log. odk_url: survey data field present provide reviewer way go back view original ODK submission order gain context around particular question value. comments: Can contain system generated user provided comments assist understanding changes made. ’s important formatting file format validation log changed. data set needs machine readable used directly apply changes data.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/articles/outputs.html","id":"special-cases","dir":"Articles","previous_headings":"Validation Logs","what":"Special Cases","title":"Understanding The Pipeline Outputs","text":"special cases validation log can used just simply correcting existing values raised. first example creating new value data set. new value created user must go end validation log create new entry. new rowid provided appropriate entry ID populated. fields new_value no_change columns also need created. case record deleted, user can provide keyword new_val column. Currently, keyword ‘Delete’. set detected pipeline rather changing value word ‘Delete’ correction function interpret instruction delete particular record data. keyword needs changed, ability pass argument correction function, targets pipeline.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Collin Schwantes. Maintainer, author. Johana Teigen. Author. Ernest Guevarra. Author. Dean Marchiori. Author. Melinda Rostal. Author. EcoHealth Alliance. Copyright holder, funder.           https://ror.org/02zv3m156","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Schwantes C, Teigen J, Guevarra E, Marchiori D, Rostal M (2025). ohcleandat: One Health Data Cleaning Quality Checking Package. R package version 1.1.3, https://One-Health-Research-Consulting.github.io/ohcleandat/.","code":"@Manual{,   title = {ohcleandat: One Health Data Cleaning and Quality Checking Package},   author = {Collin Schwantes and Johana Teigen and Ernest Guevarra and Dean Marchiori and Melinda Rostal},   year = {2025},   note = {R package version 1.1.3},   url = {https://One-Health-Research-Consulting.github.io/ohcleandat/}, }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/index.html","id":"ohcleandat-","dir":"","previous_headings":"","what":"One Health Data Cleaning and Quality Checking Package","title":"One Health Data Cleaning and Quality Checking Package","text":"package provides useful functions orchestrate analytics data cleaning pipelines One Health projects.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"One Health Data Cleaning and Quality Checking Package","text":"can install development version ohcleandat GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"one-health-research-consulting/ohcleandat\")"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"One Health Data Cleaning and Quality Checking Package","text":"help guides, check package vignettes.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/index.html","id":"contributions","dir":"","previous_headings":"","what":"Contributions","title":"One Health Data Cleaning and Quality Checking Package","text":"project uses Gitflow workflow. new feature requests done new branch based dev fork dev. New branches can take form feature/* fix/*. feature complete, automated CI checks merge checks performed pull request raised merge changes dev. package nearing release, release/x.x.x branch created head dev. used make changes convert code production level increment version number make release notes required raising PR main. PR main accepted, github release performed, using package version tag. final step deleting feature release branches merging main back dev incrementing dev version x.x.x.9000.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting Help","title":"One Health Data Cleaning and Quality Checking Package","text":"encounter clear bug, please file minimal reproducible example github.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/autobot.html","id":null,"dir":"Reference","previous_headings":"","what":"Autobot Function — autobot","title":"Autobot Function — autobot","text":"compares two columns. differences, extracts values compiles correctly formatted validation log. intended used automated formatting correction proposed data, actual updating records required happen via validation log.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/autobot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Autobot Function — autobot","text":"","code":"autobot(data, old_col, new_col, primary_key)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/autobot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Autobot Function — autobot","text":"data data.frame tibble old_col existing column formatting issues new_col new column corrections applied primary_key column uniquely identifies records data","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/autobot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Autobot Function — autobot","text":"tibble formatted validation log","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/check_id_existence.html","id":null,"dir":"Reference","previous_headings":"","what":"Check existence of ID columns across two tables — check_id_existence","title":"Check existence of ID columns across two tables — check_id_existence","text":"returns rows x without match y. Returning selected columns . wrapper around dplyr::anti_join.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/check_id_existence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check existence of ID columns across two tables — check_id_existence","text":"","code":"check_id_existence(x, y, by, select_cols, ...)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/check_id_existence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check existence of ID columns across two tables — check_id_existence","text":"x data.frame tibble containing match id check non existence y y data.frame tibble check non-existence match id x character containing match id, named different, named character vector like c(\"\" = \"b\") select_cols character vector columns select output. Note join, columns identical names data sets suffix .x .y added disambiguate. need added ensur correct column returned. ... variables passed dplyr::anti_join","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/check_id_existence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check existence of ID columns across two tables — check_id_existence","text":"tibble rows x without match y","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/check_id_existence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check existence of ID columns across two tables — check_id_existence","text":"","code":"if (FALSE) { # \\dontrun{ check_id_existence(x,                    y,                    by =  c(\"Batch_ID\" = \"batch_id\"),                    select_cols = c(\"Batch_ID\", \"iDate\", \"Farm_ID\")) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/class_to_col_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Class to Column Type lookup table — class_to_col_type","title":"Class to Column Type lookup table — class_to_col_type","text":"table links classes readr column types. Created csv file name inst/","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/class_to_col_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class to Column Type lookup table — class_to_col_type","text":"","code":"class_to_col_type"},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/class_to_col_type.html","id":"class-to-col-type","dir":"Reference","previous_headings":"","what":"class_to_col_type","title":"Class to Column Type lookup table — class_to_col_type","text":"data frame 9 rows 3 columns: col_type Type column described readr col_class Class R object matches column type col_abv Abbreviation column type readr","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/class_to_col_type.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class to Column Type lookup table — class_to_col_type","text":"class_to_col_type <- read.csv(file = \"inst/class_to_col_type.csv\") usethis::use_data(class_to_col_type,overwrite = TRUE)","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/combine_logs.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine Validation Logs — combine_logs","title":"Combine Validation Logs — combine_logs","text":"Checks existence existing validation log appends new records current run.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/combine_logs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine Validation Logs — combine_logs","text":"","code":"combine_logs(existing_log, new_log)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/combine_logs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine Validation Logs — combine_logs","text":"existing_log tibble existing validation log new_log tibble newly generated validation log","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/combine_logs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine Validation Logs — combine_logs","text":"tibble appended validation log upload","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/correct_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Correct data using validation log — correct_data","title":"Correct data using validation log — correct_data","text":"Takes validation log applies required changes data","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/correct_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correct data using validation log — correct_data","text":"","code":"correct_data(validation_log, data, primary_key)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/correct_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correct data using validation log — correct_data","text":"validation_log tibble validation log data tibble original unclean data primary_key character quoted column name unique identifier data","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/correct_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correct data using validation log — correct_data","text":"tibble semi-clean data set","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_freetext_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Free Text Log — create_freetext_log","title":"Create Free Text Log — create_freetext_log","text":"Creates custom validation log ': explain' free text responses may contain valid multi-choice options.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_freetext_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Free Text Log — create_freetext_log","text":"","code":"create_freetext_log(response_data, form_schema, url, lookup)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_freetext_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Free Text Log — create_freetext_log","text":"response_data data.frame ODK questionnaire response data form_schema data.frame ODK flattened form schema data url ODK submission URL excluding uuid identifier lookup tibble formatted lookup match questions free text responses. format must match output othertext_lookup(). function can passed function argument convenient handler value.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_freetext_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Free Text Log — create_freetext_log","text":"data.frame validation log","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_freetext_log.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Free Text Log — create_freetext_log","text":"function needs link survey question corresponding free text response. Users can use othertext_lookup() function handle , provide tibble format. See : tibble::tribble( ~name, ~other_name, question_1, question_1_other )","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_freetext_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Free Text Log — create_freetext_log","text":"","code":"if (FALSE) { # \\dontrun{ # Using othertext_lookup helper test_a <- create_freetext_log(response_data = animal_owner_semiclean,                               form_schema = animal_owner_schema,                               url = \"https://odk.xyz.io/#/projects/5/forms/project/submissions\",                               lookup = ohcleandat::othertext_lookup(questionnaire = \"animal_owner\")                               )  # using custom lookup table mylookup <- tibble::tribble(   ~name, ~other_name,   \"f2_species_own\", \"f2a_species_own_oexp\"   )    test_b <- create_freetext_log(response_data = animal_owner_semiclean,                                 form_schema = animal_owner_schema,                                 url = \"https://odk.xyz.io/#/projects/5/forms/project/submissions\",                                 lookup = mylookup                                 ) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_questionnaire_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Validation Log for Questionnaire data — create_questionnaire_log","title":"Create Validation Log for Questionnaire data — create_questionnaire_log","text":"Create Validation Log Questionnaire data","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_questionnaire_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Validation Log for Questionnaire data — create_questionnaire_log","text":"","code":"create_questionnaire_log(data, form_schema, primary_key, rule_set, url)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_questionnaire_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Validation Log for Questionnaire data — create_questionnaire_log","text":"data data fame  Input data validated form_schema data frame ODK form schema data primary_key character  character vector giving column name primary key unique row identifier data rule_set rule set class validator validate package url ODK submission URL excluding uuid identifier","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_questionnaire_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Validation Log for Questionnaire data — create_questionnaire_log","text":"data frame formatted validation log human review","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_rules_from_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a ","title":"Create a ","text":"Creates rules file template show general structure rule file.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_rules_from_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a ","text":"","code":"create_rules_from_template(   name,   dir = \"R\",   open = TRUE,   showWarnings = FALSE,   overwrite_file = FALSE )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_rules_from_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a ","text":"name String. Name rule set function e.g. create_rules_my_dataset dir String. Name directory file created. doesnt exist, folder created. open Logical. file opened? showWarnings Logical. dir.create show warnings? overwrite_file Logical. rules file name overwritten?","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_rules_from_template.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a ","text":"String. File path newly created file","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_structural_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Structural Metadata from a dataframe — create_structural_metadata","title":"Create Structural Metadata from a dataframe — create_structural_metadata","text":"metadata describes data . metadata can generated joined pre-existing metadata via field names.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_structural_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Structural Metadata from a dataframe — create_structural_metadata","text":"","code":"create_structural_metadata(   data,   primary_key = \"\",   foreign_key = \"\",   additional_elements = tibble::tibble() )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_structural_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Structural Metadata from a dataframe — create_structural_metadata","text":"data named object. Expects table work superficially lists named vectors. primary_key Character. name field serves primary key foreign_key Character. Field fields foreign keys additional_elements Empty tibble structural metadata elements types.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_structural_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Structural Metadata from a dataframe — create_structural_metadata","text":"dataframe standard metadata requirements","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_structural_metadata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Structural Metadata from a dataframe — create_structural_metadata","text":"metadata table produced following elements name = name field. taken data. description = Description field. May provided controlled vocabulary units = Units measure field. May may apply term_uri = Universal Resource Identifier term controlled vocabulary schema comments = Free text providing additional details field primary_key = TRUE FALSE, Uniquely identifies record data foreign_key = TRUE FALSE, Allows linkages data sets. Uniquely identifies records different data set","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_translation_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Translation Log — create_translation_log","title":"Create Translation Log — create_translation_log","text":"Collates free text responses '' 'notes' fields survey data. language detection performed placed log notes section possible translation.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_translation_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Translation Log — create_translation_log","text":"","code":"create_translation_log(response_data, form_schema, url)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_translation_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Translation Log — create_translation_log","text":"response_data data.frame ODK questionnaire responses form_schema data.frame flattened ODK form schema url ODK submission URL excluding uuid identifier","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_translation_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Translation Log — create_translation_log","text":"data.frame validation log","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_validation_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Validation Log — create_validation_log","title":"Create Validation Log — create_validation_log","text":"Create Validation Log","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_validation_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Validation Log — create_validation_log","text":"","code":"create_validation_log(data, primary_key, rule_set, ...)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_validation_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Validation Log — create_validation_log","text":"data data fame  Input data validated primary_key character  character vector giving column name primary key unique row identifier data rule_set rule set class validator validate package ... arguments passed validate::confront","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/create_validation_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Validation Log — create_validation_log","text":"data frame formatted validation log human review","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/detect_language.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect Language — detect_language","title":"Detect Language — detect_language","text":"function extracts top guess language piece text.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/detect_language.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect Language — detect_language","text":"","code":"detect_language(text)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/detect_language.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect Language — detect_language","text":"text character text string","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/detect_language.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect Language — detect_language","text":"character estimate language abbreviation","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/detect_language.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect Language — detect_language","text":"Utilizes stringi package encoding detector means infer language.","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/detect_language.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect Language — detect_language","text":"","code":"detect_language(text = \"buongiorno\") #> [1] \"it\""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_dropbox.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Drop Box Files — download_dropbox","title":"Download Drop Box Files — download_dropbox","text":"Downloads files dropbox given directory","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_dropbox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Drop Box Files — download_dropbox","text":"","code":"download_dropbox(dropbox_path, dropbox_filename, download_path, ...)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_dropbox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Drop Box Files — download_dropbox","text":"dropbox_path character formal folder path dropbox dropbox_filename character formal file name dropbox download_path character Local file path download file ... arguments passed rdrop2::drop_download","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_dropbox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Drop Box Files — download_dropbox","text":"returns file path successful","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_dropbox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Drop Box Files — download_dropbox","text":"","code":"if (FALSE) { # \\dontrun{    download_dropbox(dropbox_path = \"XYZ/Project-Datasets\",    dropbox_filename = \"Project dataset as at 01-02-2024.xlsx\",    download_path = here::here(\"data\"),    overwrite = TRUE) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_googledrive_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Google Drive Files — download_googledrive_files","title":"Download Google Drive Files — download_googledrive_files","text":"given Google Drive folder function find download files matching given pattern.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_googledrive_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Google Drive Files — download_googledrive_files","text":"","code":"download_googledrive_files(   key_path,   drive_path,   search_pattern,   MIME_type = NULL,   out_path )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_googledrive_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Google Drive Files — download_googledrive_files","text":"key_path character path Google authentication key drive_path character Google drive folder path search_pattern character search pattern files Google drive MIME_type character Google Drive file type, file extension, MIME type. out_path character local file directory files downloaded ","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_googledrive_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Google Drive Files — download_googledrive_files","text":"character vector files downloaded","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_googledrive_files.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download Google Drive Files — download_googledrive_files","text":"Note: relies googledrive::drive_ls() function uses search function deterministic recursively searching. Please pay attention returned.","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/download_googledrive_files.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Google Drive Files — download_googledrive_files","text":"","code":"if (FALSE) { # \\dontrun{   download_googledrive_files(   key_path = here::here(\"./key.json\"),   drive_path = \"https://drive.google.com/drive/u/0/folders/asdjfnasiffas8ef7y7y89rf\",   search_pattern = \".*\\\\.xlsx\",   out_path = here::here(\"data/project_data/\")   ) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/dropbox_upload.html","id":null,"dir":"Reference","previous_headings":"","what":"Dropbox Upload — dropbox_upload","title":"Dropbox Upload — dropbox_upload","text":"Upload local file dropbox handle authentication. Automatically zips files 300mb default.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/dropbox_upload.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dropbox Upload — dropbox_upload","text":"","code":"dropbox_upload(dataframe, file_path, dropbox_path, compress = TRUE)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/dropbox_upload.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dropbox Upload — dropbox_upload","text":"dataframe Data frame. work tabular data. Designed used Validation Log OH cleaning pipelines. file_path character. local file path upload dropbox_path character. relative dropbox path compress logical. files 300mb compressed?","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/dropbox_upload.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dropbox Upload — dropbox_upload","text":"Character. File path dropbox.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/dropbox_upload.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dropbox Upload — dropbox_upload","text":"wrapper rdrop2::drop_upload() first reads local CSV file uploads DropBox path.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/dropbox_upload.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dropbox Upload — dropbox_upload","text":"","code":"if (FALSE) { # \\dontrun{     dropbox_upload(     kzn_animal_ship_semiclean,     file_path = here::here(\"outputs/data.csv\"),     dropbox_path = \"XYZ/Data/semi_clean_data\"     ) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/expand_frictionless_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand Frictionless Metadata with structural metadata — expand_frictionless_metadata","title":"Expand Frictionless Metadata with structural metadata — expand_frictionless_metadata","text":"Loops elements structural metadata adds frictionless metadata schema. overwrite existing values remove fields datapackage metadata listed structural metadata.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/expand_frictionless_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand Frictionless Metadata with structural metadata — expand_frictionless_metadata","text":"","code":"expand_frictionless_metadata(   structural_metadata,   resource_name,   resource_path,   data_package_path,   prune_datapackage = TRUE )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/expand_frictionless_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand Frictionless Metadata with structural metadata — expand_frictionless_metadata","text":"structural_metadata Dataframe. Structural metadata create_structural_metadata update_structural_metadata resource_name Character. Item within datapackage updated resource_path Character. Path csv file data_package_path Character. Path datapackage.json file prune_datapackage Logical. properties structural metadata removed?","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/expand_frictionless_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand Frictionless Metadata with structural metadata — expand_frictionless_metadata","text":"Updates datapackage, returns nothing","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/expand_frictionless_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand Frictionless Metadata with structural metadata — expand_frictionless_metadata","text":"","code":"if (FALSE) { # \\dontrun{  # read in file data_path <- \"my/data.csv\" data <- read.csv(data_path)  # create structural metadata data_codebook  <- create_structural_metadata(data)  # update structural metadata write.csv(data_codebook,\"my/codebook.csv\", row.names = FALSE)  data_codebook_updated <- read.csv(\"my/codebook.csv\")  # create frictionless package - this is done automatically with the # deposits package my_package <-  create_package() |>  add_resource(resource_name = \"data\", data = data_path)   write_package(my_package,\"my\")  expand_frictionless_metadata(structural_metadata = data_codebook_updated,                             resource_name = \"data\",                             resource_path = data_path,                             data_package_path = \"my/datapackage.json\"                             )  } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_dropbox_val_logs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Dropbox Validation Logs — get_dropbox_val_logs","title":"Get Dropbox Validation Logs — get_dropbox_val_logs","text":"Downloads existing validation logs stored dropbox","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_dropbox_val_logs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Dropbox Validation Logs — get_dropbox_val_logs","text":"","code":"get_dropbox_val_logs(file_name, folder, path_name)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_dropbox_val_logs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Dropbox Validation Logs — get_dropbox_val_logs","text":"file_name character file name extension validation log. Note file may zipped upload 300mb. file automatically unzipped download provide file extenstion compressed file, zipped file. E.g. \"val_log.csv\" even dropbox stored \"val_log.zip\". folder character folder log saved drop box. Can NULL subfolder. path_name character default drop box path","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_dropbox_val_logs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Dropbox Validation Logs — get_dropbox_val_logs","text":"tibble Validation Log","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_dropbox_val_logs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Dropbox Validation Logs — get_dropbox_val_logs","text":"function check log exists return NULL . Else locally download file 'dropbox_validations' directory read session.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_dropbox_val_logs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Dropbox Validation Logs — get_dropbox_val_logs","text":"","code":"if (FALSE) { # \\dontrun{  get_dropbox_val_logs(file_name = \"log.csv\", folder = NULL) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_form_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Get ODK Questionnaire Schema Info — get_odk_form_schema","title":"Get ODK Questionnaire Schema Info — get_odk_form_schema","text":"function handles authentication pulling questionnaire form schema information.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_form_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get ODK Questionnaire Schema Info — get_odk_form_schema","text":"","code":"get_odk_form_schema(   url,   un = Sys.getenv(\"ODK_USERNAME\"),   pw = Sys.getenv(\"ODK_PASSWORD\"),   odkc_version = Sys.getenv(\"ODKC_VERSION\") )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_form_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get ODK Questionnaire Schema Info — get_odk_form_schema","text":"url character survey URL un character ODK account username pw character ODK account password odkc_version character ODKC Version string","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_form_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get ODK Questionnaire Schema Info — get_odk_form_schema","text":"data frame survey responses","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_form_schema.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get ODK Questionnaire Schema Info — get_odk_form_schema","text":"wrapper around ruODK package. handles setup authentication. See https://github.com/ropensci/ruODK","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_form_schema.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get ODK Questionnaire Schema Info — get_odk_form_schema","text":"","code":"if (FALSE) { # \\dontrun{     get_odk_form_schema(url =\"https://odk.xyz.io/v1/projects/5/forms/survey.svc\",     un = Sys.getenv(\"ODK_USERNAME\"),     pw = Sys.getenv(\"ODK_PASSWORD\"),     odkc_version = Sys.getenv(\"ODKC_VERSION\")) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_responses.html","id":null,"dir":"Reference","previous_headings":"","what":"Get ODK Questionnaire Response Data — get_odk_responses","title":"Get ODK Questionnaire Response Data — get_odk_responses","text":"function handles authentication pulling responses data ODK Questionnaires. raw return list 'rectangularized' data frame first. See ruODK package info happens.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_responses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get ODK Questionnaire Response Data — get_odk_responses","text":"","code":"get_odk_responses(   url,   un = Sys.getenv(\"ODK_USERNAME\"),   pw = Sys.getenv(\"ODK_PASSWORD\"),   odkc_version = Sys.getenv(\"ODKC_VERSION\") )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_responses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get ODK Questionnaire Response Data — get_odk_responses","text":"url character survey URL un character ODK account username pw character ODK account password odkc_version character ODK version","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_responses.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get ODK Questionnaire Response Data — get_odk_responses","text":"data.frame flattened survey responses","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_responses.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get ODK Questionnaire Response Data — get_odk_responses","text":"wrapper around ruODK package. handles setup authentication. See https://github.com/ropensci/ruODK","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_odk_responses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get ODK Questionnaire Response Data — get_odk_responses","text":"","code":"if (FALSE) { # \\dontrun{     get_odk_responses(url =\"https://odk.xyz.io/v1/projects/5/forms/survey.svc\",     un = Sys.getenv(\"ODK_USERNAME\"),     pw = Sys.getenv(\"ODK_PASSWORD\"),     odkc_version = Sys.getenv(\"ODKC_VERSION\")) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Precision — get_precision","title":"Get Precision — get_precision","text":"Get Precision","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Precision — get_precision","text":"","code":"get_precision(x, func = c, ...)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Precision — get_precision","text":"x Numeric. Vector gps points func Function. Apply function vector precisions. Default c values returned ... Additional arguments pass func.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_precision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Precision — get_precision","text":"output func - likely vector","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_precision.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get Precision — get_precision","text":"Nathan Layman","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_precision.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Precision — get_precision","text":"","code":"x <- c(1,100,1.11) get_precision(x,func = min) #> [1] 0.01"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_species_letter.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Species Letter — get_species_letter","title":"Get Species Letter — get_species_letter","text":"function maps relationship animal species hum_anim_id codes. use id_checker()","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_species_letter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Species Letter — get_species_letter","text":"","code":"get_species_letter(   species = c(\"human\", \"cattle\", \"small_mammal\", \"sheep\", \"goat\") )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_species_letter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Species Letter — get_species_letter","text":"species character species identifier. See argument options","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/get_species_letter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Species Letter — get_species_letter","text":"character hum_anim_id code","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/guess_col_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Guess the column type — guess_col_type","title":"Guess the column type — guess_col_type","text":"uses column class set readr column type","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/guess_col_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guess the column type — guess_col_type","text":"","code":"guess_col_type(data, default_col_abv = \"c\")"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/guess_col_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Guess the column type — guess_col_type","text":"data data.frame Data column types like guess default_col_abv string. Column type abbreviation readr::cols(). Use \"g\" guess column type.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/guess_col_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Guess the column type — guess_col_type","text":"character vector column abbreviations","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/guess_col_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Guess the column type — guess_col_type","text":"","code":"data <- data.frame(time = Sys.time(), char = \"hello\", num = 1, log = TRUE, date = Sys.Date(), list_col = list(\"hello\") )  guess_col_type(data) #>     time     char      num      log     date X.hello.  #>      \"T\"      \"c\"      \"n\"      \"l\"      \"D\"      \"c\"   ## change default value of default column abbreviation  guess_col_type(data, default_col_abv = \"g\") #>     time     char      num      log     date X.hello.  #>      \"T\"      \"c\"      \"n\"      \"l\"      \"D\"      \"c\""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/id_checker.html","id":null,"dir":"Reference","previous_headings":"","what":"ID Checker — id_checker","title":"ID Checker — id_checker","text":"General function checking correcting ID columns.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/id_checker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ID Checker — id_checker","text":"","code":"id_checker(col, type = c(\"animal\", \"hum_anim\", \"site\"), ...)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/id_checker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ID Checker — id_checker","text":"col vector ID's checked type ID type, see argument options allowable settings ... function arguments passed get_species_letter","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/id_checker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ID Checker — id_checker","text":"vector corrected ID's","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/id_checker.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ID Checker — id_checker","text":"order use autobot process correcting ID columns, new 'corrected' column created user using id_checker() function. take existing vector ID's, ID type (animal, mosquito, etc) apply bespoke corrections. can consumed autobot log.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/id_checker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ID Checker — id_checker","text":"","code":"if (FALSE) { # \\dontrun{ # with a species identifier     data |> mutate(animal_id_new = id_checker(animal_id, type = \"animal\", species = \"cattle\"))     data |> mutate(farm_id_new = id_checker(farm_id, type = \"site\"))     } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_report_urls.html","id":null,"dir":"Reference","previous_headings":"","what":"Make the URLs for the reports — make_report_urls","title":"Make the URLs for the reports — make_report_urls","text":"Several HTML reports emailed via automated process. secure URL generated download link. function used opinionated targets pipeline.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_report_urls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make the URLs for the reports — make_report_urls","text":"","code":"make_report_urls(aws_deploy_target, pattern = \"\")"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_report_urls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make the URLs for the reports — make_report_urls","text":"aws_deploy_target List. Output aws_s3_upload pattern String. Regex pattern matching file paths","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_report_urls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make the URLs for the reports — make_report_urls","text":"character URL report","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_report_urls.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Make the URLs for the reports — make_report_urls","text":"Collin Schwantes","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_zip_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get make a zip file path — make_zip_path","title":"Get make a zip file path — make_zip_path","text":"Take file path, remove extension, replace extension .zip","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_zip_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get make a zip file path — make_zip_path","text":"","code":"make_zip_path(file_path)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_zip_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get make a zip file path — make_zip_path","text":"file_path character.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_zip_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get make a zip file path — make_zip_path","text":"character. String extension replaced zip","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/make_zip_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get make a zip file path — make_zip_path","text":"","code":"file_path <- \"hello.csv\" make_zip_path(file_path) #> [1] \"hello.zip\"  file_path_with_dir <- \"foo/bar/hello.csv\" make_zip_path(file_path_with_dir) #> [1] \"foo/bar/hello.zip\""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/obfuscate_gps.html","id":null,"dir":"Reference","previous_headings":"","what":"Obfuscate GPS — obfuscate_gps","title":"Obfuscate GPS — obfuscate_gps","text":"function fuzzes gps points first adding error rounding certain number digits.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/obfuscate_gps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obfuscate GPS — obfuscate_gps","text":"","code":"obfuscate_gps(   x,   precision = 2,   fuzz = 0.125,   type = c(\"lat\", \"lon\"),   func = min,   ... )  obfuscate_lat(x, precision = 2, fuzz = 0.125)  obfuscate_lon(x, precision = 2, fuzz = 0.125)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/obfuscate_gps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obfuscate GPS — obfuscate_gps","text":"x Numeric. Vector gps points precision Integer. Number digits keep. See round details fuzz Numeric. Positive number indicating much error introduce gps measurements. used generate random uniform distribution runif(1,min = -fuzz, max = fuzz) type Character. One \"lat\" \"lon\" func Function. Function used get_precision ... Additional arguments func.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/obfuscate_gps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obfuscate GPS — obfuscate_gps","text":"Numeric. vector fuzzed rounded GPS points Numeric vector Numeric vector","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/obfuscate_gps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obfuscate GPS — obfuscate_gps","text":"","code":"# make data gps_data  <- data.frame(lat = c(1.0001, 10.22223, 4.00588),                         lon = c(2.39595, 4.506930, -60.09999901))  # Default obfuscation settings correspont to roughly a 27 by 27 km area gps_data$lat |>   obfuscate_gps(type = \"lat\") #> The data have a max precision of: 1e-05 #> The max shift from the combination of precision and fuzz is: 0.225 degrees #> [1]  0.88 10.11  3.89  # Obfuscation can be made more or less precise by changing the number of # decimal points included or modifying the amount of fuzz (error) # introduced gps_data$lon |>   obfuscate_gps(precision = 4, fuzz = 0.002, type = \"lon\") #> The data have a max precision of: 1e-08 #> The max shift from the combination of precision and fuzz is: 0.012 degrees #> The majority of the obfuscation is coming from rounding, this #>     potentially makes re-identification easier #> [1]   2.3949   4.5058 -60.1011  ### working at the poles gps_data_poles  <- data.frame(lat = c(89.0001, 89.22223, -89.8881),                               lon = c(2.39595, 4.506930, -60.09999901))   gps_data_poles$lat |>   obfuscate_gps(fuzz = 1, type = \"lat\") #> The data have a max precision of: 1e-05 #> The max shift from the combination of precision and fuzz is: 1.1 degrees #> [1]  88.60  88.82 -89.79   ### working at the 180th meridian gps_data_180  <- data.frame(lat = c(2, 3, 4),                             lon = c(179.39595, -179.506930, -178.09999901)) gps_data_180$lon |>   obfuscate_gps(fuzz = 1, type = \"lon\") #> The data have a max precision of: 1e-08 #> The max shift from the combination of precision and fuzz is: 1.1 degrees #> [1] -179.71 -178.61 -177.20  ### working NA GPS data gps_data_180  <- data.frame(lat = c(2, 3, 4),                             lon = c(179.39595, NA, -178.09999901)) gps_data_180$lon |>   obfuscate_gps(fuzz = 1, type = \"lon\") #> The data have a max precision of: 1e-08 #> The max shift from the combination of precision and fuzz is: 1.1 degrees #> [1]  178.76      NA -178.74  ### GPS is on the fritz! if (FALSE) { # \\dontrun{ gps_data_fritz <- data.frame(lat = c(91, -91, 90),                              lon = c(181.0001, -181.9877, -178.09999901)) gps_data_fritz$lon |>   obfuscate_gps(fuzz = 1, type = \"lon\")  gps_data_fritz$lat |>   obfuscate_gps(fuzz = 1, type = \"lat\") } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/othertext_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"Look-up table for 'Other' questions — othertext_lookup","title":"Look-up table for 'Other' questions — othertext_lookup","text":"Provides look table matching ODK survey questions free text response question.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/othertext_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Look-up table for 'Other' questions — othertext_lookup","text":"","code":"othertext_lookup(questionnaire = c(\"animal_owner\"))"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/othertext_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Look-up table for 'Other' questions — othertext_lookup","text":"questionnaire ODK questionnaire. Used ensure correct look table found.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/othertext_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Look-up table for 'Other' questions — othertext_lookup","text":"tibble","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/othertext_lookup.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Look-up table for 'Other' questions — othertext_lookup","text":"many ODK surveys, multiple choice question can response '' respondent can add free text response. consistent link response data match captured responses free-text collected. function provides manual look reference free text responses can compared original questions validation workflow. function can expanded providing tibble two columns: name other_name maps question name ODK question name containing '' 'free text'.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/othertext_lookup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Look-up table for 'Other' questions — othertext_lookup","text":"","code":"othertext_lookup(questionnaire = c(\"animal_owner\")) #> # A tibble: 21 × 2 #>    name                      other_name                 #>    <chr>                     <chr>                      #>  1 f2_species_own            f2a_species_own_oexp       #>  2 f6e_rvf_vax_type          f6e_rvf_vax_type_oexp      #>  3 f6a_protocol              f6a_protocol_other         #>  4 f6b_which_vax             f6c_ani_vax_num_oexp       #>  5 f6i_rvf_vax_chalenge_mult f6i_rvf_vax_chalenge_oexp  #>  6 f7b_abortion_3_which      f7b_abortion_3_which_oexp  #>  7 f7d_abortion_12_which     f7d_abortion_12_which_oexp #>  8 f7f_abortus_dispose       f7f_abortus_dispose_oexp   #>  9 f8_ani_contact            f8_ani_contact_oexp        #> 10 f8c_contact_other_sp      f8c_contact_other_sp_oexp  #> # ℹ 11 more rows"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/prune_datapackage.html","id":null,"dir":"Reference","previous_headings":"","what":"Prune field properties in a data package — prune_datapackage","title":"Prune field properties in a data package — prune_datapackage","text":"method remove properties metadata dataset datapackage","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/prune_datapackage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prune field properties in a data package — prune_datapackage","text":"","code":"prune_datapackage(my_data_schema, structural_metadata)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/prune_datapackage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prune field properties in a data package — prune_datapackage","text":"my_data_schema list. schema object frictionless structural_metadata dataframe. structural metadata dataset","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/prune_datapackage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prune field properties in a data package — prune_datapackage","text":"pruned data_schema -","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_excel_all_sheets.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads all tabs from an excel workbook — read_excel_all_sheets","title":"Reads all tabs from an excel workbook — read_excel_all_sheets","text":"given excel file, detect sheets, iteratively read sheets place list. primary keys added, primary key triplet file, sheet name, row number e.g. \"file_xlsx_sheet1_1\". Row numbering based data ingested R. R automatically skips empty rows beginning spreadsheet id 1 primary key belong first row data.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_excel_all_sheets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads all tabs from an excel workbook — read_excel_all_sheets","text":"","code":"read_excel_all_sheets(   file,   add_primary_key_field = FALSE,   primary_key = \"primary_key\" )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_excel_all_sheets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads all tabs from an excel workbook — read_excel_all_sheets","text":"file character. File path excel file add_primary_key_field Logical. primary key field added? primary_key character. column name unique identifier added data.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_excel_all_sheets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads all tabs from an excel workbook — read_excel_all_sheets","text":"list","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_excel_all_sheets.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Reads all tabs from an excel workbook — read_excel_all_sheets","text":"primary key method possible Excel forces sheet names unique.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_excel_all_sheets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reads all tabs from an excel workbook — read_excel_all_sheets","text":"","code":"if (FALSE) { # \\dontrun{ # Adding primary key field read_excel_all_sheet(file = \"test_pk.xlsx\",add_primary_key_field = TRUE)  # Don't add primary key field read_excel_all_sheet(file = \"test_pk.xlsx\")      } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_googlesheets.html","id":null,"dir":"Reference","previous_headings":"","what":"Read Google Sheets Data — read_googlesheets","title":"Read Google Sheets Data — read_googlesheets","text":"given sheet id, handles authentication reads specified sheet, sheets.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_googlesheets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read Google Sheets Data — read_googlesheets","text":"","code":"read_googlesheets(   key_path,   sheet = \"all\",   ss,   add_primary_key_field = FALSE,   primary_key = \"primary_key\",   ... )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_googlesheets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read Google Sheets Data — read_googlesheets","text":"key_path character path Google authentication key json file sheet Sheet read, sense \"worksheet\" \"tab\". ss Something identifies Google Sheet drive id URL add_primary_key_field Logical. primary key field added? primary_key character. column name unique identifier added data. ... arguments passed googlesheets4::range_read()","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_googlesheets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read Google Sheets Data — read_googlesheets","text":"tibble","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/read_googlesheets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read Google Sheets Data — read_googlesheets","text":"","code":"if (FALSE) { # \\dontrun{ read_googlesheets(ss = kzn_animal_ship_sheets, sheet = \"all\",) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/remove_deletions.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function to identify records for deletion — remove_deletions","title":"Utility function to identify records for deletion — remove_deletions","text":"Filters records matching given string.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/remove_deletions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function to identify records for deletion — remove_deletions","text":"","code":"remove_deletions(x, val = stringr::regex(\"Delete\", ignore_case = TRUE))"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/remove_deletions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function to identify records for deletion — remove_deletions","text":"x input vector val Character regex. value check inequality. Val fed stringr::str_detect pattern parameter. Defaults 'Delete' ignore case = TRUE. See stringr::str_detect details.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/remove_deletions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility function to identify records for deletion — remove_deletions","text":"logical vector","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/remove_deletions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Utility function to identify records for deletion — remove_deletions","text":"used within dplyr::filter(). function returns logical vector TRUE resulting values equal val argument. Also protects NA values. Used within verbs tidyselect::all_of() can work effectively across columns data frame. See examples","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/remove_deletions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utility function to identify records for deletion — remove_deletions","text":"","code":"data <- data.frame(\"a\" = sample(c(\"Delete\", \"Keep\",NA),size = 10,replace = TRUE))  data |>   dplyr::filter(dplyr::if_all(everything(), remove_deletions)) #>      a #> 1 Keep #> 2 Keep #> 3 <NA> #> 4 Keep #> 5 Keep #> 6 <NA> #> 7 Keep"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/set_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Get items that differ between x and y — set_diff","title":"Get items that differ between x and y — set_diff","text":"Unlike setdiff, function creates union x y removes values intersect, providing values unique X values unique Y.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/set_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get items that differ between x and y — set_diff","text":"","code":"set_diff(x, y)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/set_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get items that differ between x and y — set_diff","text":"x set values. y set values.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/set_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get items that differ between x and y — set_diff","text":"Unique values X Y, NULL unique values.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/set_diff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get items that differ between x and y — set_diff","text":"","code":"a <- 1:3 b <- 2:4  set_diff(a,b) #> [1] 1 4 # returns 1,4  x <- 1:3 y <- 1:3  set_diff(x,y) #> NULL # returns NULL"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_frictionless_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Update descriptive metadata in frictionless datapackage — update_frictionless_metadata","title":"Update descriptive metadata in frictionless datapackage — update_frictionless_metadata","text":"function overwrites descriptive metadata associated frictionless datapackage. validate metadata, check conflicts existing descriptive metadata. easy create invalid metadata.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_frictionless_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update descriptive metadata in frictionless datapackage — update_frictionless_metadata","text":"","code":"update_frictionless_metadata(descriptive_metadata, data_package_path)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_frictionless_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update descriptive metadata in frictionless datapackage — update_frictionless_metadata","text":"descriptive_metadata List descriptive metadata terms. data_package_path Character. Path datapackage.json file","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_frictionless_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update descriptive metadata in frictionless datapackage — update_frictionless_metadata","text":"invisibly writes datapackage.json","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_frictionless_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update descriptive metadata in frictionless datapackage — update_frictionless_metadata","text":"","code":"if (FALSE) { # \\dontrun{ descriptive_metadata <- list ( title = \"Example Dataset\", description = \"This is the abstract but it needs more detail\", creator = list (list (name = \"A. Person\"), list (name = \"B. Person\"), list (name = \"C. Person\"),list (name = \"F. Person\")) # , accessRights = \"open\" ) update_frictionless_metadata(descriptive_metadata = descriptive_metadata,                              data_package_path = \"data_examples/datapackage.json\" ) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_structural_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Update structural metadata — update_structural_metadata","title":"Update structural metadata — update_structural_metadata","text":"Appends rows /columns existing metadata, change primary key /adds foreign keys.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_structural_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update structural metadata — update_structural_metadata","text":"","code":"update_structural_metadata(   data,   metadata,   primary_key = \"\",   foreign_key = \"\",   additional_elements = tibble::tibble() )"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_structural_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update structural metadata — update_structural_metadata","text":"data named object. Expects table work superficially lists named vectors. metadata Data frame. Output create_structural_metadata primary_key Character. OPTIONAL Primary key data foreign_key Character. OPTIONAL Foreign key keys data additional_elements data frame. OPTIONAL Empty tibble structural metadata elements types.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_structural_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update structural metadata — update_structural_metadata","text":"data.frame","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/update_structural_metadata.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Update structural metadata — update_structural_metadata","text":"See vignette metadata examples","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/validation_checks.html","id":null,"dir":"Reference","previous_headings":"","what":"Validation Correction Checks — validation_checks","title":"Validation Correction Checks — validation_checks","text":"Validation correction tests run data validation test expectations.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/validation_checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validation Correction Checks — validation_checks","text":"","code":"validation_checks(validation_log, before_data, after_data, primary_key)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/validation_checks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validation Correction Checks — validation_checks","text":"validation_log tibble Validation log before_data tibble Data corrections after_data tibble Data corrections primary_key character primary key 'after_data'","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/validation_checks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validation Correction Checks — validation_checks","text":"NULL passed stops error","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/validation_checks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validation Correction Checks — validation_checks","text":"part OH cleaning pipelines, raw data converted 'semi-clean' data process upserting records external Validation Log. ensure corrections made expected, checks performed function. existing log exists > changes make data variables Rows unequal values log exists changes recommended > changes data. variables Rows unequal values Log exists changes recommended > number changes log variables Rows Number changing records data match records log Correct fields records updated Checks variables rows Checks variable names row indexes logs changed data.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/validation_checks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validation Correction Checks — validation_checks","text":"","code":"if (FALSE) { # \\dontrun{     validation_checks(     validation_log = kzn_animal_ship_existing_log,     before_data = kzn_animal_ship,     after_data = kzn_animal_ship_semiclean,     primary_key = \"animal_id\"     ) } # }"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/write_rds.html","id":null,"dir":"Reference","previous_headings":"","what":"Write data RDS — write_rds","title":"Write data RDS — write_rds","text":"function write RDS file R object file doesnt exist 2) object file changed.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/write_rds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write data RDS — write_rds","text":"","code":"write_rds(r_obj, rds_file, ...)"},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/write_rds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write data RDS — write_rds","text":"r_obj R object saved. Likely data frame rds_file String. Path rds file repo ... Additional arguments pass saveRDS","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/write_rds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write data RDS — write_rds","text":"Path rds file","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/reference/write_rds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write data RDS — write_rds","text":"useful working data streams (airtable, googledrive, dropbox, etc) depend account based access - particularly institution via employer. account loses access data stream entire pipeline may go . copy data stored RDS allows modify pipeline use local copy data instead.","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-113","dir":"Changelog","previous_headings":"","what":"ohcleandat 1.1.3","title":"ohcleandat 1.1.3","text":"dropbox_upload returns path dropbox file uploaded.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-112","dir":"Changelog","previous_headings":"","what":"ohcleandat 1.1.2","title":"ohcleandat 1.1.2","text":"validation logs vary number columns based type added flexible col_type variable.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-111","dir":"Changelog","previous_headings":"","what":"ohcleandat 1.1.1","title":"ohcleandat 1.1.1","text":"Fix sign issue validation checks warning duplication Make removes_deletes robust capitalization errors keyword “Delete”","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-100","dir":"Changelog","previous_headings":"","what":"ohcleandat 1.0.0","title":"ohcleandat 1.0.0","text":"changing key field logs is_valid no_change. cause breaking changes.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-0312","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.12","title":"ohcleandat 0.3.12","text":"expand_frictionless_metadata can add remove fields metadata depending structural metadata supplied.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-0311","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.11","title":"ohcleandat 0.3.11","text":"obfuscate gps can now handle NAs","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-0310","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.10","title":"ohcleandat 0.3.10","text":"datapackage.json can pruned closely follow structural metadata datasets","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-039","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.9","title":"ohcleandat 0.3.9","text":"Files 300mb zipped attempting upload dropbox. Zipped validation logs dropbox automatically unzipped.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-038","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.8","title":"ohcleandat 0.3.8","text":"Fixing bug bug fix - naming properties updated","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-037","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.7","title":"ohcleandat 0.3.7","text":"Fixing bug expand metadata - function now allows updates","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-036","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.6","title":"ohcleandat 0.3.6","text":"Adds function update descriptive metadata frictionless datapackage","code":""},{"path":[]},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-034","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.4","title":"ohcleandat 0.3.4","text":"Setups minimal structural metadata framework tabular datasets.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-033","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.3","title":"ohcleandat 0.3.3","text":"Adds control function used get_precision obfuscate_gps","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-032","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.2","title":"ohcleandat 0.3.2","text":"Fixing issue download_google_drive search pattern applied.","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-031","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.1","title":"ohcleandat 0.3.1","text":"Explicitly adding set_diff function previously hidden dependency {ecohealthalliance/airtabler} package","code":""},{"path":"https://One-Health-Research-Consulting.github.io/ohcleandat/news/index.html","id":"ohcleandat-030","dir":"Changelog","previous_headings":"","what":"ohcleandat 0.3.0","title":"ohcleandat 0.3.0","text":"Adding GPS obfuscation function - function uses two methods reduce accuracy GPS points. first adding amount error measurement user defined random uniform distribution. second rounding remove precision measurement.","code":""}]
